{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment_2_Active_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t02WfK07tKUD",
        "colab_type": "text"
      },
      "source": [
        "##Active Learning Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WWuHNqPtMBY",
        "colab_type": "text"
      },
      "source": [
        "### Importing Libraries \n",
        "Libraries used are numpy, pandas, matplotlib and sklearn for classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3tkjfPZO9Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irBxyZoPtQwR",
        "colab_type": "text"
      },
      "source": [
        "###Fetching Dataset\n",
        "Dataset used are Iris and MNIST from sklearn for testing the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3LcF0ahmltib",
        "colab": {}
      },
      "source": [
        "def fetch_data_iris():\n",
        "    iris = load_iris()\n",
        "    X = iris.data.astype('float64')\n",
        "    y = iris.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_mnist():\n",
        "    mnist = load_digits()\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIS9y9S1xhFw",
        "colab_type": "text"
      },
      "source": [
        "###Classifiers Model\n",
        "Superclass is made for different types of classifiers for major use in query by committee. The main classifier used is SVM for all the other query frameworks.The classifiers consist of SVM, Random Forest, Naive Bayes and Multinomial Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lgi65jqExxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        self.classifier = SVC(C=1, kernel='linear', probability=True)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(C=50. / train_samples,multi_class='multinomial',penalty='l1',solver='saga',tol=0.1)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        self.classifier = RandomForestClassifier(n_estimators=500)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class NbcModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        self.classifier = GaussianNB()\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m55y9T_yQ44",
        "colab_type": "text"
      },
      "source": [
        "###Train Model\n",
        "Class made for testing and training different classifiers by interfacing with the Classfiers superclass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYbXfSSfK0PL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = globals()[model_object]()\n",
        "        self.model_name = model_object         \n",
        "\n",
        "    def train(self, X_train, y_train, X_val, X_test):\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,self.test_y_predicted) = self.model_object.fit_predict(X_train, y_train, X_val, X_test)\n",
        "        return (X_train, X_val, X_test)  \n",
        "\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)\n",
        "        print('Iteration: %d Model: %s Accuracy: %f' % (i,self.model_name,classif_rate))\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOadMon9xmPl",
        "colab_type": "text"
      },
      "source": [
        "###Uncertainity Sampling\n",
        "Superclass is made for three different types of sampling as part of uncertainity sampling. The three samplings consist of Least Confidence, Margin Sampling and Entropy Sampling for both pool based and stream based strategies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-9JJ8Tql585",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class uncertainity_sampling(object) :\n",
        "    \n",
        "    def __init__(self) :\n",
        "        pass\n",
        "    def query_pool(self) :\n",
        "        pass \n",
        "    def query_stream(self) :\n",
        "        pass    \n",
        "\n",
        "class least_confidence(uncertainity_sampling) :\n",
        "\n",
        "    @staticmethod\n",
        "    def query_pool(conf_unlab , batch_size) :\n",
        "\n",
        "        sorted_prob = -np.sort(-conf_unlab , axis = 1) \n",
        "        return np.argsort(sorted_prob[:,0])[:batch_size]\n",
        "    \n",
        "    @staticmethod\n",
        "    def query_stream(conf_unlab) :\n",
        "        if np.sort(-np.sort(-conf_unlab)[:,0])[0] < 0.5 :\n",
        "            return True \n",
        "        else :\n",
        "            return False    \n",
        "\n",
        "class margin_sampling(uncertainity_sampling) :\n",
        "\n",
        "    @staticmethod\n",
        "    def query_pool(conf_unlab , batch_size) :\n",
        "\n",
        "        sorted_prob = -np.sort(-conf_unlab , axis = 1)\n",
        "        margin = sorted_prob[:,0] - sorted_prob[:,1] \n",
        "        return np.argsort(margin)[:batch_size]\n",
        "\n",
        "    @staticmethod\n",
        "    def query_stream(conf_unlab) :\n",
        "        if (-np.sort(-conf_unlab)[0,0] - (-np.sort(-conf_unlab)[0,1])) < 0.1 :\n",
        "            return True \n",
        "        else :\n",
        "            return False    \n",
        "\n",
        "class  entropy_sampling(uncertainity_sampling) :\n",
        "\n",
        "    @staticmethod\n",
        "    def query_pool(conf_unlab , batch_size) :\n",
        "        \n",
        "        entropy = (-conf_unlab * np.log2(conf_unlab)).sum(axis = 1)\n",
        "        return (np.argsort(entropy)[::-1])[:batch_size]\n",
        "\n",
        "    @staticmethod\n",
        "    def query_stream(conf_unlab ) :\n",
        "        if np.count_nonzero(conf_unlab) ==0:\n",
        "            return False\n",
        "        elif (-conf_unlab * np.log2(conf_unlab)).sum() / np.log2(conf_unlab.shape[1]) > 0.6 : \n",
        "            return True\n",
        "        else :\n",
        "            return False     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsXeSEIEygIf",
        "colab_type": "text"
      },
      "source": [
        "###Normalization\n",
        "Class made for normalizing and inversing while training and testing the data for better accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XsBJmXJl_Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Normalize():\n",
        "    \n",
        "    def normalize(self, X_train, X_unlab, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_unlab   = self.scaler.transform(X_unlab)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_unlab, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_unlab, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_unlab   = self.scaler.inverse_transform(X_unlab)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_unlab, X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p6J6cb2yslS",
        "colab_type": "text"
      },
      "source": [
        "###Random Initial Labels\n",
        "Function is used to randomly label the initial number of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXc8cKbz2pWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_initial_train(initial_num, X_total, y_total):\n",
        "    \n",
        "    np.random.seed(21)\n",
        "    random_state = check_random_state(0)\n",
        "    permutation = np.random.choice(len(X_total),\n",
        "                                   initial_num,\n",
        "                                   replace=False)\n",
        "    X_train = X_total[permutation]\n",
        "    y_train = y_total[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "    \n",
        "    return (permutation, X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75yIHnRdzH_c",
        "colab_type": "text"
      },
      "source": [
        "###Pool Based Uncertainity Sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77qx1XHrKleK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class uncertainity_active_pool(object):\n",
        "\n",
        "    def __init__(self, top_pooled, model_object, selection_function):\n",
        "        self.top_pooled = top_pooled\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = globals()[selection_function]\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test,initial_samples,max_samples):\n",
        "\n",
        "        (permutation, X_train, y_train) = random_initial_train(initial_samples, X_train_full, y_train_full)\n",
        "        self.queried = initial_samples\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ()\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_samples:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            probas_val = self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "\n",
        "            uncertain_samples = self.sample_selection_function.query_pool(probas_val, self.top_pooled)\n",
        " \n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            \n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += self.top_pooled\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUnaGw0jRrOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def call_uncertainity_active_pool(model,sampling_method,max_samples,initial_samples):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    act_pool = uncertainity_active_pool(1,model , sampling_method)\n",
        "    accuracies = act_pool.run(X_train,y_train,X_test,y_test,initial_samples,max_samples)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = random_initial_train(max_samples, X_train, y_train)\n",
        "    random_accuracies=[]\n",
        "    classifier_random = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "    for i in range(initial_samples-1,max_samples):\n",
        "        classifier_random.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_random = classifier_random.predict(X_test)\n",
        "        random_accuracies.append(accuracy_score(y_test, y_pred_random)*100)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"random_accuracies\",random_accuracies)\n",
        "    x_axis = np.linspace(initial_samples,max_samples,num=max_samples - initial_samples +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, random_accuracies, 'blue',label='random') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yKVvRibz9_B",
        "colab_type": "text"
      },
      "source": [
        "###Stream Based Uncertainity Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcO1XOJmUqHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class uncertainity_active_stream(object):\n",
        "\n",
        "    def __init__(self, model_object, selection_function):\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = globals()[selection_function]\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test,initial_samples,max_samples):\n",
        "\n",
        "        (permutation, X_train, y_train) = random_initial_train(initial_samples, X_train_full, y_train_full)\n",
        "        self.queried = initial_samples\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ()\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_samples:\n",
        "\n",
        "            active_iteration += 1\n",
        "            rand_index = np.random.choice(len(X_val))\n",
        "            probas_val = self.clf_model.model_object.classifier.predict_proba(X_val[rand_index].reshape(1,X_val.shape[1]))\n",
        "            bool_info = self.sample_selection_function.query_stream(probas_val)\n",
        " \n",
        "            if bool_info :\n",
        "                X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "                \n",
        "                X_train = np.concatenate((X_train, X_val[rand_index].reshape(1,X_val.shape[1])))\n",
        "                y_train = np.append(y_train, y_val[rand_index])\n",
        "\n",
        "                X_val = np.delete(X_val, rand_index, axis=0)\n",
        "                y_val = np.delete(y_val, rand_index, axis=0)\n",
        "\n",
        "                normalizer = Normalize()\n",
        "                X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "                self.queried += 1\n",
        "                (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "                self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "            \n",
        "        return self.clf_model.accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtdRKuFzUpue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def call_uncertainity_active_stream(model,sampling_method,max_samples,initial_samples):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    act_stream = uncertainity_active_stream(model , sampling_method)\n",
        "    accuracies = act_stream.run(X_train,y_train,X_test,y_test,initial_samples,max_samples)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = random_initial_train(max_samples, X_train, y_train)\n",
        "    random_accuracies=[]\n",
        "    classifier_random = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "    for i in range(initial_samples-1,max_samples):\n",
        "        classifier_random.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_random = classifier_random.predict(X_test)\n",
        "        random_accuracies.append(accuracy_score(y_test, y_pred_random)*100)\n",
        "\n",
        "    x_axis = np.linspace(initial_samples,max_samples,num=max_samples - initial_samples +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, random_accuracies, 'blue',label='random') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwYey6ci0NHS",
        "colab_type": "text"
      },
      "source": [
        "###Vote Entropy for QBC\n",
        "Function for vote entropy calculation for Query by Committee Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJtDmpjSai4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vote_entropy(svm,logistic,random_forest,X_val):\n",
        "    y_pred1 = svm.model_object.classifier.predict(X_val)\n",
        "    y_pred2 = logistic.model_object.classifier.predict(X_val)\n",
        "    y_pred3 = random_forest.model_object.classifier.predict(X_val)\n",
        "\n",
        "    # n_classes = svm.model_object.classifier.classes_\n",
        "    n_classes = 10\n",
        "\n",
        "    entropy = np.zeros(y_pred1.shape[0])\n",
        "\n",
        "    for i in range(y_pred1.shape[0]):\n",
        "        votes=np.zeros(n_classes)\n",
        "        votes[y_pred1[i]] = votes[y_pred1[i]] + 1\n",
        "        votes[y_pred2[i]] = votes[y_pred2[i]] + 1\n",
        "        votes[y_pred3[i]] = votes[y_pred3[i]] + 1\n",
        "\n",
        "        for j in range(n_classes):\n",
        "            if votes[j] == 0 :\n",
        "                temp = 0 \n",
        "            else :    \n",
        "                temp = (-1) * (votes[j]/n_classes) * np.log(votes[j]/n_classes)\n",
        "            entropy[i] = entropy[i] + temp\n",
        "\n",
        "    return entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlglrQpF0aP7",
        "colab_type": "text"
      },
      "source": [
        "###KL Divergence\n",
        "Function for KL Divergence calculation for Query by Committee Sampling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcAwq3y6aqO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kld(svm,logistic,random_forest,X_val):\n",
        "    y_prob1 = svm.model_object.classifier.predict_proba(X_val)\n",
        "    y_prob2 = logistic.model_object.classifier.predict_proba(X_val)\n",
        "    y_prob3 = random_forest.model_object.classifier.predict_proba(X_val)\n",
        "\n",
        "    y_prob_avg = (y_prob1 + y_prob2 + y_prob3)/3\n",
        "\n",
        "    # n_classes = svm.model_object.classifier.classes_\n",
        "    n_classes = 10\n",
        "    sum = np.zeros(y_prob1.shape[0])\n",
        "    \n",
        "    for i in range(y_prob1.shape[0]) :\n",
        "        temp = 0 \n",
        "        for j in range(y_prob1.shape[1]) :\n",
        "            if y_prob1[i,j] == 0 :\n",
        "                temp += 0\n",
        "            else :\n",
        "                temp += y_prob1[i,j] * math.log(y_prob1[i,j] / y_prob_avg[i,j])\n",
        "            if y_prob2[i,j] == 0 :\n",
        "                temp += 0\n",
        "            else :\n",
        "                temp += y_prob2[i,j] * math.log(y_prob2[i,j] / y_prob_avg[i,j])\n",
        "            if y_prob3[i,j] == 0 :\n",
        "                temp += 0\n",
        "            else :\n",
        "                temp += y_prob3[i,j] * math.log(y_prob3[i,j] / y_prob_avg[i,j])\n",
        "\n",
        "        sum[i] = temp / 3    \n",
        "    \n",
        "    # sum += (y_prob1 * np.log(y_prob1 / y_prob_avg)).sum(axis = 1)\n",
        "    # sum += (y_prob2 * np.log(y_prob2 / y_prob_avg)).sum(axis = 1)\n",
        "    # sum += (y_prob3 * np.log(y_prob3 / y_prob_avg)).sum(axis = 1)\n",
        "    # sum /= 3\n",
        "    \n",
        "    return sum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbQKpx5I0ujF",
        "colab_type": "text"
      },
      "source": [
        "###Pool Based Query by Committee Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urun7cvXasgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class qbc_active_pool(object):\n",
        "\n",
        "    def __init__(self,dis_way):\n",
        "        self.dis_way = dis_way\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test,initial_samples,max_samples):\n",
        "\n",
        "        (permutation, X_train, y_train) = random_initial_train(initial_samples, X_train_full, y_train_full)\n",
        "        self.queried = initial_samples\n",
        "        self.svm=TrainModel(SvmModel.__name__ )\n",
        "        self.logistic=TrainModel(LogModel.__name__ )\n",
        "        self.random_forest=TrainModel(RfModel.__name__ )\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "             \n",
        "        (X_train, X_val, X_test) = self.svm.train(X_train, y_train, X_val, X_test)\n",
        "        (X_train, X_val, X_test) = self.logistic.train(X_train, y_train, X_val, X_test)\n",
        "        (X_train, X_val, X_test) = self.random_forest.train(X_train, y_train, X_val, X_test)\n",
        "\n",
        "        active_iteration = 1\n",
        "        self.svm.get_test_accuracy(1, y_test)\n",
        "        self.logistic.get_test_accuracy(1, y_test)\n",
        "        self.random_forest.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_samples:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            dis_array = globals()[self.dis_way](self.svm,self.logistic,self.random_forest,X_val)\n",
        "            if self.dis_way == 'vote_entropy':\n",
        "                index_selected = np.argmax(dis_array)\n",
        "            else: \n",
        "                index_selected = np.argmax(dis_array)    \n",
        "                # print(index_selected,\" yoyo \",dis_array[index_selected])\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            \n",
        "            X_train = np.concatenate((X_train, X_val[index_selected:index_selected+1]))\n",
        "            y_train = np.concatenate((y_train, y_val[index_selected:index_selected+1]))\n",
        "\n",
        "            X_val = np.delete(X_val, index_selected, axis=0)\n",
        "            y_val = np.delete(y_val, index_selected, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += 1\n",
        "\n",
        "            (X_train, X_val, X_test) = self.svm.train(X_train, y_train, X_val, X_test)\n",
        "            (X_train, X_val, X_test) = self.logistic.train(X_train, y_train, X_val, X_test)\n",
        "            (X_train, X_val, X_test) = self.random_forest.train(X_train, y_train, X_val, X_test)\n",
        "            self.svm.get_test_accuracy(active_iteration, y_test)\n",
        "            self.logistic.get_test_accuracy(active_iteration, y_test)\n",
        "            self.random_forest.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        print ('Intermediate accuracies SVM: ', self.svm.accuracies)\n",
        "        print ('Intermediate Accuracies Logistic Regression: ', self.logistic.accuracies)\n",
        "        print ('Intermediate Accuracies Random Forests: ', self.random_forest.accuracies)\n",
        "        return self.svm.accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnXinLYSa9zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def call_qbc_active_pool(dis_way,max_samples,initial_samples):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    act_pool = qbc_active_pool(dis_way)\n",
        "    accuracies = act_pool.run(X_train,y_train,X_test,y_test,initial_samples,max_samples)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = random_initial_train(max_samples, X_train, y_train)\n",
        "    random_accuracies=[]\n",
        "    classifier_random = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "    for i in range(initial_samples-1,max_samples):\n",
        "        classifier_random.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_random = classifier_random.predict(X_test)\n",
        "        random_accuracies.append(accuracy_score(y_test, y_pred_random)*100)\n",
        "\n",
        "    x_axis = np.linspace(initial_samples,max_samples,num=max_samples - initial_samples +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, random_accuracies, 'blue',label='random') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jql0DKkX0_Sm",
        "colab_type": "text"
      },
      "source": [
        "###Stream Based Query by Committee Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prNvKjXhbDDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class qbc_active_stream(object):\n",
        "\n",
        "    def __init__(self,dis_way):\n",
        "        self.dis_way = dis_way\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test,initial_samples,max_samples):\n",
        "\n",
        "        (permutation, X_train, y_train) = random_initial_train(initial_samples, X_train_full, y_train_full)\n",
        "        self.queried = initial_samples\n",
        "        self.samplecount = [initial_samples]\n",
        "        self.svm=TrainModel(SvmModel.__name__ )\n",
        "        self.logistic=TrainModel(LogModel.__name__ )\n",
        "        self.random_forest=TrainModel(RfModel.__name__ )\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "             \n",
        "        (X_train, X_val, X_test) = self.svm.train(X_train, y_train, X_val, X_test)\n",
        "        (X_train, X_val, X_test) = self.logistic.train(X_train, y_train, X_val, X_test)\n",
        "        (X_train, X_val, X_test) = self.random_forest.train(X_train, y_train, X_val, X_test)\n",
        "\n",
        "        active_iteration = 1\n",
        "        self.svm.get_test_accuracy(1, y_test)\n",
        "        self.logistic.get_test_accuracy(1, y_test)\n",
        "        self.random_forest.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_samples:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            rand_index = np.random.choice(X_val.shape[0])\n",
        "            dis_array = globals()[self.dis_way](self.svm,self.logistic,self.random_forest,X_val[rand_index].reshape(1,X_val.shape[1]))\n",
        "            \n",
        "            if self.dis_way == 'kld' :\n",
        "                if dis_array[0] > 0.04 :\n",
        "                    bool_take = True\n",
        "                else :\n",
        "                    bool_take = False        \n",
        "            if self.dis_way == 'vote_entropy' :\n",
        "                if dis_array[0] > 0.5 :\n",
        "                    bool_take = True\n",
        "                else :\n",
        "                    bool_take = False\n",
        " \n",
        "            if bool_take :\n",
        "                X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "                \n",
        "                X_train = np.concatenate((X_train, X_val[rand_index].reshape(1,X_val.shape[1])))\n",
        "                y_train = np.append(y_train, y_val[rand_index])\n",
        "\n",
        "                X_val = np.delete(X_val, rand_index, axis=0)\n",
        "                y_val = np.delete(y_val, rand_index, axis=0)\n",
        "\n",
        "                normalizer = Normalize()\n",
        "                X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "                self.queried += 1\n",
        "\n",
        "                (X_train, X_val, X_test) = self.svm.train(X_train, y_train, X_val, X_test)\n",
        "                (X_train, X_val, X_test) = self.logistic.train(X_train, y_train, X_val, X_test)\n",
        "                (X_train, X_val, X_test) = self.random_forest.train(X_train, y_train, X_val, X_test)\n",
        "                self.svm.get_test_accuracy(active_iteration, y_test)\n",
        "                self.logistic.get_test_accuracy(active_iteration, y_test)\n",
        "                self.random_forest.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "\n",
        "        print ('Intermediate accuracies SVM: ', self.svm.accuracies)\n",
        "        print ('Intermediate Accuracies Logistic Regression: ', self.logistic.accuracies)\n",
        "        print ('Intermediate Accuracies Random Forests: ', self.random_forest.accuracies)\n",
        "\n",
        "        return self.svm.accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO8Ekun9bDMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def call_qbc_active_stream(dis_way,max_samples,initial_samples):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    act_stream = qbc_active_stream(dis_way)\n",
        "    accuracies = act_stream.run(X_train,y_train,X_test,y_test,initial_samples,max_samples)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = random_initial_train(max_samples, X_train, y_train)\n",
        "    random_accuracies=[]\n",
        "    classifier_random = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "    for i in range(initial_samples-1,max_samples):\n",
        "        classifier_random.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_random = classifier_random.predict(X_test)\n",
        "        random_accuracies.append(accuracy_score(y_test, y_pred_random)*100)\n",
        "\n",
        "    x_axis = np.linspace(initial_samples,max_samples,num=max_samples - initial_samples +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, random_accuracies, 'blue',label='random') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3er6_0bL1cKz",
        "colab_type": "text"
      },
      "source": [
        "###Pool Based Diversity Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eD_gGXu5E9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class diversity_sampling_pool(object):\n",
        "\n",
        "    def __init__(self, model_object):\n",
        "        self.model_object = model_object\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test,initial_samples,max_samples):\n",
        "\n",
        "        self.queried = initial_samples\n",
        "        n_clusters=initial_samples\n",
        "        kmeans = KMeans(n_clusters, random_state=0).fit(X_train_full)\n",
        "\n",
        "        cluster_map = pd.DataFrame()\n",
        "        cluster_map['cluster'] = kmeans.labels_  \n",
        "        cluster_map.reset_index(level=0, inplace=True)\n",
        "\n",
        "        initial_indices = np.array([])\n",
        "        np.random.seed(21)\n",
        "        for i in range(n_clusters):\n",
        "            cluster_current = np.asarray(cluster_map[cluster_map.cluster == i]['index'],int)\n",
        "            index = np.random.choice(cluster_current)\n",
        "            initial_indices = np.append(initial_indices,index)\n",
        "        initial_indices = initial_indices.astype(int)\n",
        "        X_train = X_train_full[initial_indices]\n",
        "        y_train = y_train_full[initial_indices]\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, initial_indices, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, initial_indices, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_samples:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            distances = euclidean_distances(X_val, X_train)\n",
        "            min_distances = distances.min(axis=1)\n",
        "            selected_index = np.argmax(min_distances)\n",
        "            value = min_distances[selected_index]\n",
        "\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            \n",
        "            X_train = np.concatenate((X_train, X_val[selected_index:selected_index+1]))\n",
        "            y_train = np.concatenate((y_train, y_val[selected_index:selected_index+1]))\n",
        "\n",
        "            X_val = np.delete(X_val, selected_index, axis=0)\n",
        "            y_val = np.delete(y_val, selected_index, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += 1\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "            print(value)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z3T6ogC6A3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def call_diversity_sampling_pool(model,max_samples,initial_samples):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    diversity = diversity_sampling_pool(model)\n",
        "    accuracies = diversity.run(X_train,y_train,X_test,y_test,initial_samples,max_samples)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = random_initial_train(max_samples, X_train, y_train)\n",
        "    random_accuracies=[]\n",
        "    classifier_random = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "    for i in range(initial_samples-1,max_samples):\n",
        "        classifier_random.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_random = classifier_random.predict(X_test)\n",
        "        random_accuracies.append(accuracy_score(y_test, y_pred_random)*100)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"random_accuracies\",random_accuracies)\n",
        "    x_axis = np.linspace(initial_samples,max_samples,num=max_samples - initial_samples +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, random_accuracies, 'blue',label='random') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQThuCRf1jp7",
        "colab_type": "text"
      },
      "source": [
        "###Stream Based Diversity Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaeXChtHXuYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class diversity_sampling_stream(object):\n",
        "\n",
        "    def __init__(self, model_object):\n",
        "        self.model_object = model_object\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test,initial_samples,max_samples):\n",
        "\n",
        "        self.queried = initial_samples\n",
        "        n_clusters=initial_samples\n",
        "        kmeans = KMeans(n_clusters, random_state=0).fit(X_train_full)\n",
        "\n",
        "        cluster_map = pd.DataFrame()\n",
        "        cluster_map['cluster'] = kmeans.labels_  \n",
        "        cluster_map.reset_index(level=0, inplace=True)\n",
        "\n",
        "        initial_indices = np.array([])\n",
        "        np.random.seed(21)\n",
        "        for i in range(n_clusters):\n",
        "            cluster_current = np.asarray(cluster_map[cluster_map.cluster == i]['index'],int)\n",
        "            index = np.random.choice(cluster_current)\n",
        "            initial_indices = np.append(initial_indices,index)\n",
        "        initial_indices = initial_indices.astype(int)\n",
        "        X_train = X_train_full[initial_indices]\n",
        "        y_train = y_train_full[initial_indices]\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, initial_indices, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, initial_indices, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_samples:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            np.random.seed(21)\n",
        "            selected_index = np.random.choice(X_val.shape[0])\n",
        "            distances = euclidean_distances(X_val[selected_index:selected_index+1], X_train)\n",
        "            dist = np.min(distances)\n",
        "            if dist >=1:\n",
        "\n",
        "                X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "                \n",
        "                X_train = np.concatenate((X_train, X_val[selected_index:selected_index+1]))\n",
        "                y_train = np.concatenate((y_train, y_val[selected_index:selected_index+1]))\n",
        "\n",
        "                X_val = np.delete(X_val, selected_index, axis=0)\n",
        "                y_val = np.delete(y_val, selected_index, axis=0)\n",
        "\n",
        "                normalizer = Normalize()\n",
        "                X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "                self.queried += 1\n",
        "                (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "                self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkE8NyQZceWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def call_diversity_sampling_stream(model,max_samples,initial_samples):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    diversity = diversity_sampling_stream(model)\n",
        "    accuracies = diversity.run(X_train,y_train,X_test,y_test,initial_samples,max_samples)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = random_initial_train(max_samples, X_train, y_train)\n",
        "    random_accuracies=[]\n",
        "    classifier_random = SVC(C=1, kernel='linear', probability=True)\n",
        "\n",
        "    for i in range(initial_samples-1,max_samples):\n",
        "        classifier_random.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_random = classifier_random.predict(X_test)\n",
        "        random_accuracies.append(accuracy_score(y_test, y_pred_random)*100)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"random_accuracies\",random_accuracies)\n",
        "    x_axis = np.linspace(initial_samples,max_samples,num=max_samples - initial_samples +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, random_accuracies, 'blue',label='random') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4amKgkR82OQK",
        "colab_type": "text"
      },
      "source": [
        "###Cluster Strategy without Retention of Initial Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQgl2kjDN8pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cluster_strategy(limited_budget):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    n_clusters = 20\n",
        "    kmeans = KMeans(n_clusters, random_state=0).fit(X_train)\n",
        "\n",
        "    kmeans.score(X_train)\n",
        "    cluster_map = pd.DataFrame()\n",
        "    cluster_map['cluster'] = kmeans.labels_  \n",
        "    cluster_map.reset_index(level=0, inplace=True)\n",
        "    len(cluster_map[cluster_map.cluster == 1])\n",
        "    queried_indices = np.array([])\n",
        "    y_train_new=np.zeros(y_train.shape[0])\n",
        "\n",
        "    for i in range(n_clusters): \n",
        "        np.random.seed(33)\n",
        "        cluster_current = np.asarray(cluster_map[cluster_map.cluster == i]['index'],int)\n",
        "        # select_limit = int(np.ceil(limited_budget/len(cluster_current)))\n",
        "        select_limit = int(np.ceil((len(cluster_current) * limited_budget)/X_train.shape[0]))\n",
        "        selected = np.random.choice(cluster_current,select_limit,replace=False)\n",
        "        selected = selected.astype(int)\n",
        "        queried_indices = np.concatenate((queried_indices,selected))\n",
        "        y_cluster_classes = y_train[selected]\n",
        "        cluster_class = np.bincount(y_cluster_classes).argmax()\n",
        "        y_train_new[cluster_current] = cluster_class\n",
        "        # y_train_new[selected] = y_train[selected]\n",
        "\n",
        "    classifier = SVC(C=1, kernel='linear', probability=True)\n",
        "    classifier.fit(X_train,y_train_new)\n",
        "    y_pred_new = classifier.predict(X_test)\n",
        "    accuracy_with = accuracy_score(y_test,y_pred_new)\n",
        "    queried_indices\n",
        "    queried_indices = np.asarray(queried_indices)\n",
        "    queried_indices = queried_indices.astype(int)\n",
        "    classifier.fit(X_train[queried_indices],y_train[queried_indices])\n",
        "    accuracy_without = accuracy_score(y_test,classifier.predict(X_test))\n",
        "\n",
        "    print(\"Accuracy with only limited labelled points: \",accuracy_without)\n",
        "    print(\"Accuracy after labelling using clustering: \",accuracy_with)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhxRW_IQ2Vkh",
        "colab_type": "text"
      },
      "source": [
        "###Cluster Strategy with Retention of Initial Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N57zf2NTN8sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cluster_strategy_2(limited_budget):\n",
        "    (X,y) = fetch_data_mnist()\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    n_clusters = 20\n",
        "    kmeans = KMeans(n_clusters, random_state=0).fit(X_train)\n",
        "\n",
        "    kmeans.score(X_train)\n",
        "    cluster_map = pd.DataFrame()\n",
        "    cluster_map['cluster'] = kmeans.labels_  \n",
        "    cluster_map.reset_index(level=0, inplace=True)\n",
        "    len(cluster_map[cluster_map.cluster == 1])\n",
        "    queried_indices = np.array([])\n",
        "    y_train_new=np.zeros(y_train.shape[0])\n",
        "\n",
        "    for i in range(n_clusters): \n",
        "        cluster_current = np.asarray(cluster_map[cluster_map.cluster == i]['index'],int)\n",
        "        # select_limit = int(np.ceil(limited_budget/len(cluster_current)))\n",
        "        select_limit = int(np.ceil((len(cluster_current) * limited_budget)/X_train.shape[0]))\n",
        "        np.random.seed(33)\n",
        "        selected = np.random.choice(cluster_current,select_limit,replace=False)\n",
        "        selected = selected.astype(int)\n",
        "        queried_indices = np.concatenate((queried_indices,selected))\n",
        "        y_cluster_classes = y_train[selected]\n",
        "        cluster_class = np.bincount(y_cluster_classes).argmax()\n",
        "        y_train_new[cluster_current] = cluster_class\n",
        "        y_train_new[selected] = y_train[selected]\n",
        "\n",
        "    classifier = SVC(C=1, kernel='linear', probability=True)\n",
        "    classifier.fit(X_train,y_train_new)\n",
        "    y_pred_new = classifier.predict(X_test)\n",
        "    accuracy_with = accuracy_score(y_test,y_pred_new)\n",
        "    queried_indices\n",
        "    queried_indices = np.asarray(queried_indices)\n",
        "    queried_indices = queried_indices.astype(int)\n",
        "    classifier.fit(X_train[queried_indices],y_train[queried_indices])\n",
        "    accuracy_without = accuracy_score(y_test,classifier.predict(X_test))\n",
        "\n",
        "    print(\"Accuracy with only limited labelled points: \",accuracy_without)\n",
        "    print(\"Accuracy after labelling using clustering: \",accuracy_with)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMGDL-Xf2mTw",
        "colab_type": "text"
      },
      "source": [
        "###Main Menu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-YGGWczdCQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start():\n",
        "    while True:\n",
        "        print('Active Learning Machine Learning Assignment 2')\n",
        "        print()\n",
        "        print('Please choose the Query Strategy Framework or select 4 for Cluster Analysis :')\n",
        "        print('1.Uncertainty Sampling')\n",
        "        print('2.Query by Committee')\n",
        "        print('3.Diversity Sampling')\n",
        "        print('4.Cluster Analysis')\n",
        "        print('0.Exit')\n",
        "        a = int(input('Enter the number: '))\n",
        "\n",
        "        if a==0:\n",
        "            break\n",
        "        \n",
        "        if a!=1 and a!=2 and a!=3 and a!=4:\n",
        "            print('Please enter a valid number!')\n",
        "            continue\n",
        "        \n",
        "        if a==4:\n",
        "            print()\n",
        "            print('Please choose from the following:')\n",
        "            print('1.Cluster Analysis with Retention of initial labels')\n",
        "            print('2.Cluster Analysis without Retention')\n",
        "            print('0.Exit')\n",
        "            b = int(input('Enter the number:'))\n",
        "\n",
        "            if b==0:\n",
        "                break\n",
        "            print()\n",
        "            print('Please choose from budget options:')\n",
        "            print('1.Low Budget(30 samples)')\n",
        "            print('2.High Budget(100 samples)')\n",
        "            c = int(input('Enter the number:'))\n",
        "            if b==1:\n",
        "                cluster_strategy_2(30 if c==1 else 100)\n",
        "            else:\n",
        "                cluster_strategy(30 if c==1 else 100)    \n",
        "            continue\n",
        "\n",
        "        print()\n",
        "        print('Please choose the type of sampling:')\n",
        "        print('1.Pool-based')\n",
        "        print('2.Stream-based')\n",
        "        print('0.Exit')\n",
        "        b = int(input('Enter the number: '))\n",
        "            \n",
        "        if b!=1 and b!=2:\n",
        "            break\n",
        "\n",
        "        if a==1:\n",
        "            print()\n",
        "            print('Please choose the Uncertainty Measure:')\n",
        "            print('1.Margin')\n",
        "            print('2.Entropy')\n",
        "            print('3.Least Confidence')\n",
        "            print('0.exit')\n",
        "            c = int(input('Enter the number: ')) \n",
        "\n",
        "            if c!=1 and c!=2 and c!=3:\n",
        "                break\n",
        "\n",
        "            if b==1:\n",
        "                if c==1:\n",
        "                    call_uncertainity_active_pool(SvmModel.__name__,margin_sampling.__name__,50,20)\n",
        "                elif c==2:\n",
        "                    call_uncertainity_active_pool(SvmModel.__name__,entropy_sampling.__name__,50,20)\n",
        "                elif c==3:\n",
        "                    call_uncertainity_active_pool(SvmModel.__name__,least_confidence.__name__,50,20)\n",
        "\n",
        "            \n",
        "            elif b==2:\n",
        "                if c==1:\n",
        "                    call_uncertainity_active_stream(SvmModel.__name__,margin_sampling.__name__,50,20)\n",
        "                elif c==2:\n",
        "                    call_uncertainity_active_stream(SvmModel.__name__,entropy_sampling.__name__,50,20)\n",
        "                elif c==3:\n",
        "                    call_uncertainity_active_stream(SvmModel.__name__,least_confidence.__name__,50,20)    \n",
        "\n",
        "\n",
        "\n",
        "        elif a==2:\n",
        "            print()\n",
        "            print('Please choose the Disagreement Measure:')\n",
        "            print('1.Vote Entropy')\n",
        "            print('2.KL Divergence')\n",
        "            print('0.exit')\n",
        "            c = int(input('Enter the number: '))\n",
        "\n",
        "            if c!=1 and c!=2:\n",
        "                break\n",
        "\n",
        "            if b==1:\n",
        "                if c==1:\n",
        "                    call_qbc_active_pool('vote_entropy',50,20)\n",
        "                elif c==2:\n",
        "                    call_qbc_active_pool('kld',50,20)\n",
        "\n",
        "            elif b==2:\n",
        "                if c==1:\n",
        "                    call_qbc_active_stream('vote_entropy',50,20)\n",
        "                elif c==2:\n",
        "                    call_qbc_active_stream('kld',50,20)\n",
        "\n",
        "        elif a==3:\n",
        "            if b==1:\n",
        "                call_diversity_sampling_pool(SvmModel.__name__,50,20)\n",
        "            elif b==2:\n",
        "                call_diversity_sampling_stream(SvmModel.__name__,50,20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ciVybDR2tCm",
        "colab_type": "text"
      },
      "source": [
        "###Run this cell for the Main Menu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O49AcxAGiML_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_ZKrAfttrhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}